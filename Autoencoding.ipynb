{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import necessary packages.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import he_uniform\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 2]\n",
      "[1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "dict1 = {}\n",
    "dict1[1] = 1\n",
    "dict1[3] = 1\n",
    "dict1[2] = 2\n",
    "print(list(dict1.keys()))\n",
    "print(list(dict1.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102442, 13217)\n"
     ]
    }
   ],
   "source": [
    "#Load functional signatures of premises.\n",
    "\n",
    "X = np.load('Fun.npy')\n",
    "\n",
    "(num_contexts, num_fun) = X.shape\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select training and test samples.\n",
    "\n",
    "indices = list(range(num_contexts))\n",
    "shuffle(indices)\n",
    "\n",
    "X_train = X[indices][: int(num_contexts * 0.8)]\n",
    "X_test = X[indices][int(num_contexts * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               3383808   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 13217)             3396769   \n",
      "=================================================================\n",
      "Total params: 6,780,577\n",
      "Trainable params: 6,780,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "81953/81953 [==============================] - 102s 1ms/step - loss: 0.0084 - acc: 0.2057\n",
      "Epoch 2/300\n",
      "81953/81953 [==============================] - 128s 2ms/step - loss: 0.0053 - acc: 0.3784\n",
      "Epoch 3/300\n",
      "81953/81953 [==============================] - 112s 1ms/step - loss: 0.0045 - acc: 0.4704\n",
      "Epoch 4/300\n",
      "81953/81953 [==============================] - 108s 1ms/step - loss: 0.0042 - acc: 0.5044\n",
      "Epoch 5/300\n",
      "81953/81953 [==============================] - 87s 1ms/step - loss: 0.0039 - acc: 0.5191\n",
      "Epoch 6/300\n",
      "81953/81953 [==============================] - 103s 1ms/step - loss: 0.0038 - acc: 0.5258\n",
      "Epoch 7/300\n",
      "81953/81953 [==============================] - 160s 2ms/step - loss: 0.0037 - acc: 0.5324\n",
      "Epoch 8/300\n",
      "81953/81953 [==============================] - 198s 2ms/step - loss: 0.0036 - acc: 0.5367\n",
      "Epoch 9/300\n",
      "81953/81953 [==============================] - 182s 2ms/step - loss: 0.0035 - acc: 0.5398\n",
      "Epoch 10/300\n",
      "81953/81953 [==============================] - 169s 2ms/step - loss: 0.0034 - acc: 0.5424\n",
      "Epoch 11/300\n",
      "81953/81953 [==============================] - 162s 2ms/step - loss: 0.0033 - acc: 0.5423\n",
      "Epoch 12/300\n",
      "81953/81953 [==============================] - 231s 3ms/step - loss: 0.0033 - acc: 0.5455\n",
      "Epoch 13/300\n",
      "81953/81953 [==============================] - 180s 2ms/step - loss: 0.0032 - acc: 0.5457\n",
      "Epoch 14/300\n",
      "81953/81953 [==============================] - 188s 2ms/step - loss: 0.0032 - acc: 0.5472\n",
      "Epoch 15/300\n",
      "81953/81953 [==============================] - 296s 4ms/step - loss: 0.0031 - acc: 0.5512\n",
      "Epoch 16/300\n",
      "81953/81953 [==============================] - 312s 4ms/step - loss: 0.0031 - acc: 0.5491\n",
      "Epoch 17/300\n",
      "81953/81953 [==============================] - 291s 4ms/step - loss: 0.0030 - acc: 0.5501\n",
      "Epoch 18/300\n",
      "81953/81953 [==============================] - 247s 3ms/step - loss: 0.0030 - acc: 0.5517\n",
      "Epoch 19/300\n",
      "81953/81953 [==============================] - 181s 2ms/step - loss: 0.0030 - acc: 0.5520\n",
      "Epoch 20/300\n",
      "81953/81953 [==============================] - 66s 800us/step - loss: 0.0029 - acc: 0.5500\n",
      "Epoch 21/300\n",
      "81953/81953 [==============================] - 111s 1ms/step - loss: 0.0029 - acc: 0.5531\n",
      "Epoch 22/300\n",
      "81953/81953 [==============================] - 96s 1ms/step - loss: 0.0029 - acc: 0.5544\n",
      "Epoch 23/300\n",
      "81953/81953 [==============================] - 74s 902us/step - loss: 0.0029 - acc: 0.5541\n",
      "Epoch 24/300\n",
      "81953/81953 [==============================] - 91s 1ms/step - loss: 0.0028 - acc: 0.5539\n",
      "Epoch 25/300\n",
      "81953/81953 [==============================] - 78s 950us/step - loss: 0.0028 - acc: 0.5529\n",
      "Epoch 26/300\n",
      "81953/81953 [==============================] - 67s 814us/step - loss: 0.0028 - acc: 0.5557\n",
      "Epoch 27/300\n",
      "81953/81953 [==============================] - 62s 760us/step - loss: 0.0028 - acc: 0.5555\n",
      "Epoch 28/300\n",
      "81953/81953 [==============================] - 64s 776us/step - loss: 0.0027 - acc: 0.5543\n",
      "Epoch 29/300\n",
      "81953/81953 [==============================] - 72s 874us/step - loss: 0.0027 - acc: 0.5530\n",
      "Epoch 30/300\n",
      "81953/81953 [==============================] - 64s 781us/step - loss: 0.0027 - acc: 0.5556\n",
      "Epoch 31/300\n",
      "81953/81953 [==============================] - 67s 820us/step - loss: 0.0027 - acc: 0.5539\n",
      "Epoch 32/300\n",
      "81953/81953 [==============================] - 69s 848us/step - loss: 0.0027 - acc: 0.5536\n",
      "Epoch 33/300\n",
      "81953/81953 [==============================] - 61s 746us/step - loss: 0.0026 - acc: 0.5570\n",
      "Epoch 34/300\n",
      "81953/81953 [==============================] - 65s 790us/step - loss: 0.0026 - acc: 0.5555\n",
      "Epoch 35/300\n",
      "81953/81953 [==============================] - 65s 797us/step - loss: 0.0026 - acc: 0.5571\n",
      "Epoch 36/300\n",
      "81953/81953 [==============================] - 57s 693us/step - loss: 0.0026 - acc: 0.5570\n",
      "Epoch 37/300\n",
      "81953/81953 [==============================] - 56s 688us/step - loss: 0.0026 - acc: 0.5574\n",
      "Epoch 38/300\n",
      "81953/81953 [==============================] - 54s 663us/step - loss: 0.0026 - acc: 0.5562\n",
      "Epoch 39/300\n",
      "81953/81953 [==============================] - 54s 658us/step - loss: 0.0026 - acc: 0.5551\n",
      "Epoch 40/300\n",
      "81953/81953 [==============================] - 59s 717us/step - loss: 0.0025 - acc: 0.5551\n",
      "Epoch 41/300\n",
      "81953/81953 [==============================] - 54s 661us/step - loss: 0.0025 - acc: 0.5544\n",
      "Epoch 42/300\n",
      "81953/81953 [==============================] - 99s 1ms/step - loss: 0.0025 - acc: 0.5531\n",
      "Epoch 43/300\n",
      "81953/81953 [==============================] - 182s 2ms/step - loss: 0.0025 - acc: 0.5558\n",
      "Epoch 44/300\n",
      "81953/81953 [==============================] - 86s 1ms/step - loss: 0.0025 - acc: 0.5533\n",
      "Epoch 45/300\n",
      "81953/81953 [==============================] - 72s 873us/step - loss: 0.0025 - acc: 0.5556\n",
      "Epoch 46/300\n",
      "81953/81953 [==============================] - 58s 711us/step - loss: 0.0025 - acc: 0.5538\n",
      "Epoch 47/300\n",
      "81953/81953 [==============================] - 63s 774us/step - loss: 0.0025 - acc: 0.5558\n",
      "Epoch 48/300\n",
      "81953/81953 [==============================] - 65s 793us/step - loss: 0.0025 - acc: 0.5552\n",
      "Epoch 49/300\n",
      "81953/81953 [==============================] - 57s 700us/step - loss: 0.0024 - acc: 0.5549\n",
      "Epoch 50/300\n",
      "81953/81953 [==============================] - 57s 691us/step - loss: 0.0024 - acc: 0.5539\n",
      "Epoch 51/300\n",
      "81953/81953 [==============================] - 56s 678us/step - loss: 0.0024 - acc: 0.5577\n",
      "Epoch 52/300\n",
      "81953/81953 [==============================] - 52s 635us/step - loss: 0.0024 - acc: 0.5561\n",
      "Epoch 53/300\n",
      "81953/81953 [==============================] - 53s 652us/step - loss: 0.0024 - acc: 0.5528\n",
      "Epoch 54/300\n",
      "81953/81953 [==============================] - 54s 664us/step - loss: 0.0024 - acc: 0.5537\n",
      "Epoch 55/300\n",
      "81953/81953 [==============================] - 57s 694us/step - loss: 0.0024 - acc: 0.5581\n",
      "Epoch 56/300\n",
      "81953/81953 [==============================] - 54s 658us/step - loss: 0.0023 - acc: 0.5556\n",
      "Epoch 57/300\n",
      "81953/81953 [==============================] - 52s 638us/step - loss: 0.0023 - acc: 0.5579\n",
      "Epoch 58/300\n",
      "81953/81953 [==============================] - 55s 666us/step - loss: 0.0024 - acc: 0.5563\n",
      "Epoch 59/300\n",
      "81953/81953 [==============================] - 54s 660us/step - loss: 0.0023 - acc: 0.5540\n",
      "Epoch 60/300\n",
      "81953/81953 [==============================] - 54s 662us/step - loss: 0.0024 - acc: 0.5585\n",
      "Epoch 61/300\n",
      "81953/81953 [==============================] - 53s 652us/step - loss: 0.0023 - acc: 0.5571\n",
      "Epoch 62/300\n",
      "81953/81953 [==============================] - 53s 648us/step - loss: 0.0023 - acc: 0.5556\n",
      "Epoch 63/300\n",
      "81953/81953 [==============================] - 53s 647us/step - loss: 0.0023 - acc: 0.5540\n",
      "Epoch 64/300\n",
      "81953/81953 [==============================] - 59s 719us/step - loss: 0.0023 - acc: 0.5544\n",
      "Epoch 65/300\n",
      "81953/81953 [==============================] - 55s 669us/step - loss: 0.0023 - acc: 0.5563\n",
      "Epoch 66/300\n",
      "81953/81953 [==============================] - 53s 653us/step - loss: 0.0023 - acc: 0.5551\n",
      "Epoch 67/300\n",
      "81953/81953 [==============================] - 54s 659us/step - loss: 0.0022 - acc: 0.5530\n",
      "Epoch 68/300\n",
      "81953/81953 [==============================] - 58s 713us/step - loss: 0.0022 - acc: 0.5532\n",
      "Epoch 69/300\n",
      "81953/81953 [==============================] - 54s 660us/step - loss: 0.0022 - acc: 0.5565\n",
      "Epoch 70/300\n",
      "81953/81953 [==============================] - 55s 668us/step - loss: 0.0022 - acc: 0.5562\n",
      "Epoch 71/300\n",
      "81953/81953 [==============================] - 55s 676us/step - loss: 0.0023 - acc: 0.5563\n",
      "Epoch 72/300\n",
      "81953/81953 [==============================] - 54s 654us/step - loss: 0.0022 - acc: 0.5554\n",
      "Epoch 73/300\n",
      "81953/81953 [==============================] - 53s 651us/step - loss: 0.0023 - acc: 0.5538\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81953/81953 [==============================] - 55s 671us/step - loss: 0.0022 - acc: 0.5548\n",
      "Epoch 75/300\n",
      "81953/81953 [==============================] - 56s 687us/step - loss: 0.0022 - acc: 0.5561\n",
      "Epoch 76/300\n",
      "81953/81953 [==============================] - 56s 685us/step - loss: 0.0022 - acc: 0.5561\n",
      "Epoch 77/300\n",
      "81953/81953 [==============================] - 54s 658us/step - loss: 0.0022 - acc: 0.5536\n",
      "Epoch 78/300\n",
      "81953/81953 [==============================] - 55s 676us/step - loss: 0.0023 - acc: 0.5530\n",
      "Epoch 79/300\n",
      "81953/81953 [==============================] - 54s 655us/step - loss: 0.0022 - acc: 0.5533\n",
      "Epoch 80/300\n",
      "81953/81953 [==============================] - 53s 645us/step - loss: 0.0021 - acc: 0.5552\n",
      "Epoch 81/300\n",
      "81953/81953 [==============================] - 56s 681us/step - loss: 0.0022 - acc: 0.5538\n",
      "Epoch 82/300\n",
      "81953/81953 [==============================] - 56s 681us/step - loss: 0.0022 - acc: 0.5550\n",
      "Epoch 83/300\n",
      "81953/81953 [==============================] - 54s 662us/step - loss: 0.0022 - acc: 0.5567\n",
      "Epoch 84/300\n",
      "81953/81953 [==============================] - 56s 686us/step - loss: 0.0022 - acc: 0.5546\n",
      "Epoch 85/300\n",
      "81953/81953 [==============================] - 54s 655us/step - loss: 0.0021 - acc: 0.5532\n",
      "Epoch 86/300\n",
      "81953/81953 [==============================] - 53s 650us/step - loss: 0.0022 - acc: 0.5539\n",
      "Epoch 87/300\n",
      "81953/81953 [==============================] - 55s 673us/step - loss: 0.0021 - acc: 0.5555\n",
      "Epoch 88/300\n",
      "81953/81953 [==============================] - 69s 843us/step - loss: 0.0022 - acc: 0.5561\n",
      "Epoch 89/300\n",
      "81953/81953 [==============================] - 54s 664us/step - loss: 0.0022 - acc: 0.5545\n",
      "Epoch 90/300\n",
      "81953/81953 [==============================] - 69s 836us/step - loss: 0.0023 - acc: 0.5575\n",
      "Epoch 91/300\n",
      "81953/81953 [==============================] - 63s 766us/step - loss: 0.0021 - acc: 0.5566\n",
      "Epoch 92/300\n",
      "81953/81953 [==============================] - 60s 728us/step - loss: 0.0021 - acc: 0.5547\n",
      "Epoch 93/300\n",
      "81953/81953 [==============================] - 60s 737us/step - loss: 0.0021 - acc: 0.5554\n",
      "Epoch 94/300\n",
      "81953/81953 [==============================] - 66s 801us/step - loss: 0.0022 - acc: 0.5588\n",
      "Epoch 95/300\n",
      "81953/81953 [==============================] - 61s 750us/step - loss: 0.0022 - acc: 0.5554\n",
      "Epoch 96/300\n",
      "81953/81953 [==============================] - 66s 808us/step - loss: 0.0021 - acc: 0.5561\n",
      "Epoch 97/300\n",
      "81953/81953 [==============================] - 62s 761us/step - loss: 0.0021 - acc: 0.5550\n",
      "Epoch 98/300\n",
      "81953/81953 [==============================] - 62s 760us/step - loss: 0.0021 - acc: 0.5560\n",
      "Epoch 99/300\n",
      "81953/81953 [==============================] - 63s 770us/step - loss: 0.0022 - acc: 0.5559\n",
      "Epoch 100/300\n",
      "81953/81953 [==============================] - 64s 782us/step - loss: 0.0022 - acc: 0.5529\n",
      "Epoch 101/300\n",
      "81953/81953 [==============================] - 65s 792us/step - loss: 0.0020 - acc: 0.5558\n",
      "Epoch 102/300\n",
      "81953/81953 [==============================] - 65s 790us/step - loss: 0.0022 - acc: 0.5572\n",
      "Epoch 103/300\n",
      "81953/81953 [==============================] - 63s 770us/step - loss: 0.0021 - acc: 0.5543\n",
      "Epoch 104/300\n",
      "81953/81953 [==============================] - 63s 769us/step - loss: 0.0022 - acc: 0.5565\n",
      "Epoch 105/300\n",
      "81953/81953 [==============================] - 66s 810us/step - loss: 0.0021 - acc: 0.5564\n",
      "Epoch 106/300\n",
      "81953/81953 [==============================] - 66s 803us/step - loss: 0.0022 - acc: 0.5547\n",
      "Epoch 107/300\n",
      "81953/81953 [==============================] - 58s 713us/step - loss: 0.0020 - acc: 0.5562\n",
      "Epoch 108/300\n",
      "81953/81953 [==============================] - 71s 861us/step - loss: 0.0020 - acc: 0.5550\n",
      "Epoch 109/300\n",
      "81953/81953 [==============================] - 71s 866us/step - loss: 0.0020 - acc: 0.5575\n",
      "Epoch 110/300\n",
      "81953/81953 [==============================] - 67s 818us/step - loss: 0.0020 - acc: 0.5565\n",
      "Epoch 111/300\n",
      "81953/81953 [==============================] - 65s 787us/step - loss: 0.0023 - acc: 0.5548\n",
      "Epoch 112/300\n",
      "81953/81953 [==============================] - 63s 770us/step - loss: 0.0021 - acc: 0.5578\n",
      "Epoch 113/300\n",
      "81953/81953 [==============================] - 61s 748us/step - loss: 0.0020 - acc: 0.5573\n",
      "Epoch 114/300\n",
      "81953/81953 [==============================] - 65s 797us/step - loss: 0.0020 - acc: 0.5569\n",
      "Epoch 115/300\n",
      "81953/81953 [==============================] - 59s 722us/step - loss: 0.0020 - acc: 0.5554\n",
      "Epoch 116/300\n",
      "81953/81953 [==============================] - 66s 805us/step - loss: 0.0020 - acc: 0.5550\n",
      "Epoch 117/300\n",
      "81953/81953 [==============================] - 72s 876us/step - loss: 0.0021 - acc: 0.5582\n",
      "Epoch 118/300\n",
      "81953/81953 [==============================] - 51s 624us/step - loss: 0.0020 - acc: 0.5597\n",
      "Epoch 119/300\n",
      "81953/81953 [==============================] - 59s 718us/step - loss: 0.0021 - acc: 0.5561\n",
      "Epoch 120/300\n",
      "81953/81953 [==============================] - 67s 818us/step - loss: 0.0020 - acc: 0.5600\n",
      "Epoch 121/300\n",
      "81953/81953 [==============================] - 181s 2ms/step - loss: 0.0021 - acc: 0.5549\n",
      "Epoch 122/300\n",
      "81953/81953 [==============================] - 105s 1ms/step - loss: 0.0020 - acc: 0.5559\n",
      "Epoch 123/300\n",
      "81953/81953 [==============================] - 122s 1ms/step - loss: 0.0020 - acc: 0.5592\n",
      "Epoch 124/300\n",
      "81953/81953 [==============================] - 145s 2ms/step - loss: 0.0020 - acc: 0.5563\n",
      "Epoch 125/300\n",
      "81953/81953 [==============================] - 108s 1ms/step - loss: 0.0021 - acc: 0.5573\n",
      "Epoch 126/300\n",
      "81953/81953 [==============================] - 92s 1ms/step - loss: 0.0020 - acc: 0.5577\n",
      "Epoch 127/300\n",
      "81953/81953 [==============================] - 82s 999us/step - loss: 0.0020 - acc: 0.5578\n",
      "Epoch 128/300\n",
      "81953/81953 [==============================] - 78s 952us/step - loss: 0.0019 - acc: 0.5565\n",
      "Epoch 129/300\n",
      "81953/81953 [==============================] - 60s 731us/step - loss: 0.0020 - acc: 0.5564\n",
      "Epoch 130/300\n",
      "81953/81953 [==============================] - 78s 947us/step - loss: 0.0020 - acc: 0.5573\n",
      "Epoch 131/300\n",
      "81953/81953 [==============================] - 59s 715us/step - loss: 0.0021 - acc: 0.5567\n",
      "Epoch 132/300\n",
      "81953/81953 [==============================] - 57s 694us/step - loss: 0.0019 - acc: 0.5583\n",
      "Epoch 133/300\n",
      "81953/81953 [==============================] - 55s 673us/step - loss: 0.0020 - acc: 0.5556\n",
      "Epoch 134/300\n",
      "81953/81953 [==============================] - 59s 718us/step - loss: 0.0019 - acc: 0.5584\n",
      "Epoch 135/300\n",
      "81953/81953 [==============================] - 54s 656us/step - loss: 0.0020 - acc: 0.5576\n",
      "Epoch 136/300\n",
      "81953/81953 [==============================] - 54s 658us/step - loss: 0.0020 - acc: 0.5596\n",
      "Epoch 137/300\n",
      "81953/81953 [==============================] - 62s 752us/step - loss: 0.0019 - acc: 0.5553\n",
      "Epoch 138/300\n",
      "81953/81953 [==============================] - 55s 668us/step - loss: 0.0019 - acc: 0.5578\n",
      "Epoch 139/300\n",
      "81953/81953 [==============================] - 61s 741us/step - loss: 0.0019 - acc: 0.5578\n",
      "Epoch 140/300\n",
      "81953/81953 [==============================] - 57s 697us/step - loss: 0.0022 - acc: 0.5561\n",
      "Epoch 141/300\n",
      "81953/81953 [==============================] - 54s 655us/step - loss: 0.0020 - acc: 0.5577\n",
      "Epoch 142/300\n",
      "81953/81953 [==============================] - 57s 701us/step - loss: 0.0020 - acc: 0.5570\n",
      "Epoch 143/300\n",
      "81953/81953 [==============================] - 58s 704us/step - loss: 0.0019 - acc: 0.5576\n",
      "Epoch 144/300\n",
      "81953/81953 [==============================] - 52s 639us/step - loss: 0.0020 - acc: 0.5577\n",
      "Epoch 145/300\n",
      "81953/81953 [==============================] - 56s 684us/step - loss: 0.0019 - acc: 0.5578\n",
      "Epoch 146/300\n",
      "81953/81953 [==============================] - 74s 904us/step - loss: 0.0019 - acc: 0.5581\n",
      "Epoch 147/300\n",
      "81953/81953 [==============================] - 59s 715us/step - loss: 0.0021 - acc: 0.5577\n",
      "Epoch 148/300\n",
      "81953/81953 [==============================] - 51s 623us/step - loss: 0.0020 - acc: 0.5554\n",
      "Epoch 149/300\n",
      "81953/81953 [==============================] - 96s 1ms/step - loss: 0.0021 - acc: 0.5568\n",
      "Epoch 150/300\n",
      "81953/81953 [==============================] - 67s 823us/step - loss: 0.0019 - acc: 0.5556\n",
      "Epoch 151/300\n",
      "81953/81953 [==============================] - 65s 792us/step - loss: 0.0020 - acc: 0.5602\n",
      "Epoch 152/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81953/81953 [==============================] - 74s 905us/step - loss: 0.0019 - acc: 0.5585\n",
      "Epoch 153/300\n",
      "81953/81953 [==============================] - 59s 720us/step - loss: 0.0019 - acc: 0.5563\n",
      "Epoch 154/300\n",
      "81953/81953 [==============================] - 54s 656us/step - loss: 0.0018 - acc: 0.5573\n",
      "Epoch 155/300\n",
      "81953/81953 [==============================] - 56s 686us/step - loss: 0.0018 - acc: 0.5537\n",
      "Epoch 156/300\n",
      "81953/81953 [==============================] - 70s 860us/step - loss: 0.0019 - acc: 0.5585\n",
      "Epoch 157/300\n",
      "81953/81953 [==============================] - 67s 823us/step - loss: 0.0021 - acc: 0.5568\n",
      "Epoch 158/300\n",
      "81953/81953 [==============================] - 63s 772us/step - loss: 0.0022 - acc: 0.5550\n",
      "Epoch 159/300\n",
      "81953/81953 [==============================] - 61s 743us/step - loss: 0.0019 - acc: 0.5589\n",
      "Epoch 160/300\n",
      "81953/81953 [==============================] - 83s 1ms/step - loss: 0.0020 - acc: 0.5587\n",
      "Epoch 161/300\n",
      "81953/81953 [==============================] - 62s 755us/step - loss: 0.0018 - acc: 0.5577\n",
      "Epoch 162/300\n",
      "81953/81953 [==============================] - 65s 788us/step - loss: 0.0019 - acc: 0.5573\n",
      "Epoch 163/300\n",
      "81953/81953 [==============================] - 57s 701us/step - loss: 0.0023 - acc: 0.5574\n",
      "Epoch 164/300\n",
      "81953/81953 [==============================] - 53s 652us/step - loss: 0.0019 - acc: 0.5579\n",
      "Epoch 165/300\n",
      "81953/81953 [==============================] - 55s 670us/step - loss: 0.0018 - acc: 0.5575\n",
      "Epoch 166/300\n",
      "81953/81953 [==============================] - 53s 649us/step - loss: 0.0019 - acc: 0.5611\n",
      "Epoch 167/300\n",
      "81953/81953 [==============================] - 63s 766us/step - loss: 0.0021 - acc: 0.5593\n",
      "Epoch 168/300\n",
      "81953/81953 [==============================] - 57s 701us/step - loss: 0.0019 - acc: 0.5582\n",
      "Epoch 169/300\n",
      "81953/81953 [==============================] - 109s 1ms/step - loss: 0.0020 - acc: 0.5579\n",
      "Epoch 170/300\n",
      "81953/81953 [==============================] - 117s 1ms/step - loss: 0.0019 - acc: 0.5603\n",
      "Epoch 171/300\n",
      "81953/81953 [==============================] - 104s 1ms/step - loss: 0.0019 - acc: 0.5578\n",
      "Epoch 172/300\n",
      "81953/81953 [==============================] - 119s 1ms/step - loss: 0.0021 - acc: 0.5583\n",
      "Epoch 173/300\n",
      "81953/81953 [==============================] - 189s 2ms/step - loss: 0.0018 - acc: 0.5583\n",
      "Epoch 174/300\n",
      "81953/81953 [==============================] - 259s 3ms/step - loss: 0.0018 - acc: 0.5581\n",
      "Epoch 175/300\n",
      "81953/81953 [==============================] - 302s 4ms/step - loss: 0.0018 - acc: 0.5576\n",
      "Epoch 176/300\n",
      "81953/81953 [==============================] - 388s 5ms/step - loss: 0.0020 - acc: 0.5587\n",
      "Epoch 177/300\n",
      "81953/81953 [==============================] - 309s 4ms/step - loss: 0.0018 - acc: 0.5587\n",
      "Epoch 178/300\n",
      "81953/81953 [==============================] - 234s 3ms/step - loss: 0.0019 - acc: 0.5556\n",
      "Epoch 179/300\n",
      "81953/81953 [==============================] - 154s 2ms/step - loss: 0.0018 - acc: 0.5586\n",
      "Epoch 180/300\n",
      "81953/81953 [==============================] - 2552s 31ms/step - loss: 0.0019 - acc: 0.5597\n",
      "Epoch 181/300\n",
      "81953/81953 [==============================] - 229s 3ms/step - loss: 0.0018 - acc: 0.5582\n",
      "Epoch 182/300\n",
      "81953/81953 [==============================] - 4477s 55ms/step - loss: 0.0018 - acc: 0.5605\n",
      "Epoch 183/300\n",
      "81953/81953 [==============================] - 240s 3ms/step - loss: 0.0018 - acc: 0.5590\n",
      "Epoch 184/300\n",
      "81953/81953 [==============================] - 10966s 134ms/step - loss: 0.0020 - acc: 0.5599\n",
      "Epoch 185/300\n",
      "81953/81953 [==============================] - 10994s 134ms/step - loss: 0.0020 - acc: 0.5559\n",
      "Epoch 186/300\n",
      "81953/81953 [==============================] - 2523s 31ms/step - loss: 0.0018 - acc: 0.5589\n",
      "Epoch 187/300\n",
      "55296/81953 [===================>..........] - ETA: 2:15 - loss: 0.0019 - acc: 0.5613"
     ]
    }
   ],
   "source": [
    "#Autoencoder.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, kernel_initializer = he_uniform(), activation = 'tanh', input_shape = (num_fun,)))\n",
    "model.add(Dense(num_fun, kernel_initializer = he_uniform(), activation = 'relu'))\n",
    "model.compile(optimizer = RMSprop(decay = 1e-8), loss = 'mse', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, X_train, epochs = 300, batch_size = 2048, shuffle = True, verbose = 1)\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "acc_values = history_dict['acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label = 'Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0016.\n",
      "Test accuracy: 57.91%.\n"
     ]
    }
   ],
   "source": [
    "#Test autoencoder.\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, X_test, verbose = 0)\n",
    "print('Test loss:', str(round(test_loss, 4)) + '.')\n",
    "print('Test accuracy:', str(round(100*test_acc, 2)) + '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102442, 256)\n"
     ]
    }
   ],
   "source": [
    "#Save embedded functional signatures.\n",
    "\n",
    "weights = model.layers[0].get_weights()\n",
    "X = np.tanh(np.dot(X, weights[0]) + weights[1]).astype('float32')\n",
    "print(X.shape)\n",
    "\n",
    "np.save('Conj_tokens_auto', X[:32524])\n",
    "np.save('Ax_tokens_auto', X[32524:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
